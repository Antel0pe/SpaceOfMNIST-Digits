{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FknFTrThKEAx"
      },
      "outputs": [],
      "source": [
        "!pip install -q python-igraph scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the transformation pipeline:\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: (x > 0.5).float()),  # Binarize the image\n",
        "    transforms.Lambda(lambda x: x.view(-1))           # Flatten into a 784-dim vector\n",
        "])\n",
        "\n",
        "# Load the training set (set download=True if running for the first time)\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Get indices for images where the label is 1\n",
        "indices = (mnist_train.targets == 1).nonzero().squeeze()\n",
        "\n",
        "# Create a subset containing only the '1's\n",
        "mnist_train_ones = Subset(mnist_train, indices)\n",
        "\n",
        "print(f\"Total number of '1' images in the training set: {len(mnist_train_ones)}\")\n",
        "\n",
        "# Stack all 784-dim vectors from the filtered dataset\n",
        "all_vectors = torch.stack([img for img, _ in mnist_train_ones])\n",
        "unique_vectors = torch.unique(all_vectors, dim=0)\n",
        "\n",
        "print(f\"Total images in mnist_train_ones: {all_vectors.shape[0]}\")\n",
        "print(f\"Unique images: {unique_vectors.shape[0]}\")\n",
        "\n",
        "if all_vectors.shape[0] == unique_vectors.shape[0]:\n",
        "    print(\"All 784-dimensional vectors are unique.\")\n",
        "else:\n",
        "    print(\"There are duplicates in the 784-dimensional vectors.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC5DAs7NLqJW",
        "outputId": "ff80d075-2014-41e2-caaa-599118411319"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of '1' images in the training set: 6742\n",
            "Total images in mnist_train_ones: 6742\n",
            "Unique images: 6726\n",
            "There are duplicates in the 784-dimensional vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import igraph as ig\n",
        "\n",
        "def visualize_threshold_graph_igraph_weighted(unique_vectors, distance_threshold):\n",
        "    \"\"\"\n",
        "    Builds a weighted graph with python-igraph where each unique vector is a node\n",
        "    and an edge is added between nodes if their Euclidean distance is <= distance_threshold.\n",
        "    The edge is weighted by the real Euclidean distance between the nodes.\n",
        "\n",
        "    Args:\n",
        "        unique_vectors (torch.Tensor or np.array): Array/tensor of shape (n, 784) containing unique images.\n",
        "        distance_threshold (float): Maximum Euclidean distance for adding an edge between two nodes.\n",
        "\n",
        "    Returns:\n",
        "        g (igraph.Graph): The constructed weighted graph.\n",
        "    \"\"\"\n",
        "    # Convert tensor to numpy array if necessary.\n",
        "    if hasattr(unique_vectors, 'numpy'):\n",
        "        X = unique_vectors.numpy()\n",
        "    else:\n",
        "        X = unique_vectors\n",
        "\n",
        "    n = X.shape[0]\n",
        "    print(f\"Building weighted graph for {n} nodes...\")\n",
        "\n",
        "    # Use NearestNeighbors to find all pairs within the distance threshold.\n",
        "    nbrs = NearestNeighbors(radius=distance_threshold, algorithm='auto').fit(X)\n",
        "    distances, indices = nbrs.radius_neighbors(X)\n",
        "\n",
        "    # Build lists of edges and corresponding weights.\n",
        "    edge_list = []\n",
        "    weights = []\n",
        "    for i, (dists, neigh) in enumerate(zip(distances, indices)):\n",
        "        # For each neighbor j of node i, add edge only if i < j to avoid duplicates.\n",
        "        for d, j in zip(dists, neigh):\n",
        "            if i < j:\n",
        "                edge_list.append((i, j))\n",
        "                weights.append(d)\n",
        "\n",
        "    # Create an undirected graph using python-igraph.\n",
        "    g = ig.Graph(n=n, edges=edge_list, directed=False)\n",
        "    # Set the edge weight attribute.\n",
        "    g.es['weight'] = weights\n",
        "\n",
        "    print(f\"Weighted graph built with {len(edge_list)} edges.\")\n",
        "    return g\n",
        "\n",
        "# Example usage:\n",
        "g = visualize_threshold_graph_igraph_weighted(unique_vectors, distance_threshold=6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyGcfyrdLrJk",
        "outputId": "d517bf8c-80d5-4bc7-e5f1-9d384bef6e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building weighted graph for 6726 nodes...\n",
            "Weighted graph built with 4681902 edges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Assume:\n",
        "#   - g is your igraph Graph from the previous cell.\n",
        "#   - unique_vectors is a torch.Tensor of shape (n, 784) where n is the number of nodes in g.\n",
        "\n",
        "# Compute connected components of the graph.\n",
        "clusters = g.connected_components()\n",
        "# Find the index (label) of the largest component.\n",
        "largest_cluster_index = np.argmax(clusters.sizes())\n",
        "# Get the indices of nodes belonging to the largest component.\n",
        "vertex_indices = [i for i, comp in enumerate(clusters.membership) if comp == largest_cluster_index]\n",
        "\n",
        "print(f\"Largest connected component has {len(vertex_indices)} nodes.\")\n",
        "\n",
        "# Convert the vertex indices list to a torch tensor.\n",
        "vertex_indices_tensor = torch.tensor(vertex_indices, dtype=torch.long)\n",
        "\n",
        "# Use these indices to select the corresponding vectors.\n",
        "largest_component_vectors = unique_vectors[vertex_indices_tensor]\n",
        "print(\"Shape of largest component vectors:\", largest_component_vectors.shape)\n",
        "\n",
        "# Create a TensorDataset with these vectors.\n",
        "unique_dataset = TensorDataset(largest_component_vectors)\n",
        "print(\"TensorDataset created with largest connected component vectors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hQdBmLMLmJ",
        "outputId": "99d3fb6f-4ba5-457d-836c-6d18cf1163d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest connected component has 6631 nodes.\n",
            "Shape of largest component vectors: torch.Size([6631, 784])\n",
            "TensorDataset created with largest connected component vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a simple autoencoder architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder: 784 -> 256 -> 128 -> latent_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder: latent_dim -> 128 -> 256 -> 784\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 784),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "    def get_latent(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 256\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "latent_dim = 32\n",
        "\n",
        "# Create DataLoader for the unique dataset\n",
        "unique_loader = DataLoader(unique_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Set up device and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Autoencoder(latent_dim=latent_dim).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Use binary cross entropy since inputs are binary\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop for the autoencoder on unique vectors\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch in unique_loader:\n",
        "        images = batch[0].to(device)  # images shape: [batch_size, 784]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(unique_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Extract latent representations for analysis or visualization\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(unique_loader))[0].to(device)\n",
        "    latent_codes = model.get_latent(sample_batch)\n",
        "    print(\"Latent representations shape:\", latent_codes.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMpuVpocMg2r",
        "outputId": "45d81a19-a4ef-4452-8862-4f4ac077efc3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.4346\n",
            "Epoch [2/50], Loss: 0.1282\n",
            "Epoch [3/50], Loss: 0.1161\n",
            "Epoch [4/50], Loss: 0.1112\n",
            "Epoch [5/50], Loss: 0.0946\n",
            "Epoch [6/50], Loss: 0.0728\n",
            "Epoch [7/50], Loss: 0.0641\n",
            "Epoch [8/50], Loss: 0.0560\n",
            "Epoch [9/50], Loss: 0.0521\n",
            "Epoch [10/50], Loss: 0.0506\n",
            "Epoch [11/50], Loss: 0.0498\n",
            "Epoch [12/50], Loss: 0.0491\n",
            "Epoch [13/50], Loss: 0.0486\n",
            "Epoch [14/50], Loss: 0.0482\n",
            "Epoch [15/50], Loss: 0.0479\n",
            "Epoch [16/50], Loss: 0.0475\n",
            "Epoch [17/50], Loss: 0.0466\n",
            "Epoch [18/50], Loss: 0.0429\n",
            "Epoch [19/50], Loss: 0.0393\n",
            "Epoch [20/50], Loss: 0.0380\n",
            "Epoch [21/50], Loss: 0.0370\n",
            "Epoch [22/50], Loss: 0.0360\n",
            "Epoch [23/50], Loss: 0.0350\n",
            "Epoch [24/50], Loss: 0.0339\n",
            "Epoch [25/50], Loss: 0.0326\n",
            "Epoch [26/50], Loss: 0.0318\n",
            "Epoch [27/50], Loss: 0.0311\n",
            "Epoch [28/50], Loss: 0.0305\n",
            "Epoch [29/50], Loss: 0.0301\n",
            "Epoch [30/50], Loss: 0.0295\n",
            "Epoch [31/50], Loss: 0.0290\n",
            "Epoch [32/50], Loss: 0.0284\n",
            "Epoch [33/50], Loss: 0.0280\n",
            "Epoch [34/50], Loss: 0.0275\n",
            "Epoch [35/50], Loss: 0.0269\n",
            "Epoch [36/50], Loss: 0.0265\n",
            "Epoch [37/50], Loss: 0.0259\n",
            "Epoch [38/50], Loss: 0.0253\n",
            "Epoch [39/50], Loss: 0.0246\n",
            "Epoch [40/50], Loss: 0.0241\n",
            "Epoch [41/50], Loss: 0.0236\n",
            "Epoch [42/50], Loss: 0.0234\n",
            "Epoch [43/50], Loss: 0.0230\n",
            "Epoch [44/50], Loss: 0.0227\n",
            "Epoch [45/50], Loss: 0.0225\n",
            "Epoch [46/50], Loss: 0.0223\n",
            "Epoch [47/50], Loss: 0.0221\n",
            "Epoch [48/50], Loss: 0.0218\n",
            "Epoch [49/50], Loss: 0.0217\n",
            "Epoch [50/50], Loss: 0.0214\n",
            "Latent representations shape: torch.Size([256, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def compare_distances(model, dataset, device, sample_size=50):\n",
        "    # Randomly sample sample_size images from the dataset\n",
        "    indices = torch.randperm(len(dataset))[:sample_size]\n",
        "    sample = torch.stack([dataset[i][0] for i in indices]).to(device)  # [sample_size, 784]\n",
        "\n",
        "    # Get latent representation for the sample\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        latent = model.get_latent(sample)  # [sample_size, latent_dim]\n",
        "\n",
        "    # Compute pairwise Euclidean distances in the original and latent spaces\n",
        "    dist_original = torch.cdist(sample, sample, p=2)\n",
        "    dist_latent = torch.cdist(latent, latent, p=2)\n",
        "\n",
        "    # Compute correlation between the flattened distance matrices\n",
        "    corr = np.corrcoef(dist_original.cpu().numpy().flatten(),\n",
        "                       dist_latent.cpu().numpy().flatten())[0, 1]\n",
        "    print(\"Correlation (Euclidean distances) between original and latent spaces:\", corr)\n",
        "\n",
        "    return dist_original, dist_latent\n"
      ],
      "metadata": {
        "id": "JF8-2SnPNFxt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_original, dist_latent = compare_distances(model, unique_dataset, device, sample_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq8o7MbxNjyv",
        "outputId": "1db89255-08fa-44b3-933a-7ed09a5e1b72"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation (Euclidean distances) between original and latent spaces: 0.8464987402608786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute latent representations for each unique vector using the autoencoder\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    latent_vectors = model.get_latent(unique_vectors)\n",
        "\n",
        "print(\"Latent representations shape:\", latent_vectors.shape)\n",
        "\n",
        "# Build a weighted graph from the latent representations using the pre-defined function\n",
        "g_latent = visualize_threshold_graph_igraph_weighted(latent_vectors, distance_threshold=6)\n",
        "\n",
        "# Find connected components in the latent graph\n",
        "clusters_latent = g_latent.connected_components()\n",
        "largest_component_index = np.argmax(clusters_latent.sizes())\n",
        "largest_component_nodes = clusters_latent[largest_component_index]\n",
        "\n",
        "# Create a subgraph of the largest connected component\n",
        "subgraph = g_latent.subgraph(largest_component_nodes)\n",
        "\n",
        "# Print the number of nodes and edges in the largest connected component\n",
        "print(\"Largest connected component:\")\n",
        "print(\"Number of nodes:\", subgraph.vcount())\n",
        "print(\"Number of edges:\", subgraph.ecount())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE7_4jWANx7E",
        "outputId": "0bb4d0ae-d3de-43d4-ed77-42c559d45bf3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent representations shape: torch.Size([6726, 32])\n",
            "Building weighted graph for 6726 nodes...\n",
            "Weighted graph built with 107336 edges.\n",
            "Largest connected component:\n",
            "Number of nodes: 6464\n",
            "Number of edges: 107242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_graph_connectivity(g_orig, g_latent):\n",
        "    \"\"\"\n",
        "    For each node, print the neighbors in the original and latent graphs,\n",
        "    and compute the symmetric difference between the two neighbor sets.\n",
        "    Then, identify nodes with the greatest differences.\n",
        "    \"\"\"\n",
        "    differences = {}\n",
        "    for node in range(g_orig.vcount()):\n",
        "        # Get neighbor sets from both graphs\n",
        "        neighbors_orig = set(g_orig.neighbors(node))\n",
        "        neighbors_latent = set(g_latent.neighbors(node))\n",
        "        # Compute symmetric difference\n",
        "        diff = neighbors_orig.symmetric_difference(neighbors_latent)\n",
        "        differences[node] = diff\n",
        "\n",
        "        # print(f\"Node {node}:\")\n",
        "        # print(f\"  Original neighbors: {sorted(neighbors_orig)}\")\n",
        "        # print(f\"  Latent neighbors:   {sorted(neighbors_latent)}\")\n",
        "        # print(f\"  Difference:         {sorted(diff)}\\n\")\n",
        "\n",
        "    # Identify nodes with the greatest differences\n",
        "    diff_counts = {node: len(diff) for node, diff in differences.items()}\n",
        "    max_diff_nodes = sorted(diff_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    print(\"Nodes with greatest connectivity differences:\")\n",
        "    for node, count in max_diff_nodes:\n",
        "        print(f\"  Node {node} has {count} differing connections.\")\n",
        "\n",
        "    return differences\n",
        "\n",
        "# Compare connectivity between the original graph 'g' and the latent graph 'g_latent'\n",
        "diffs = compare_graph_connectivity(g, g_latent)\n",
        "\n",
        "# Print total edge counts for both graphs\n",
        "print(f\"\\nTotal edges in original graph: {g.ecount()}\")\n",
        "print(f\"Total edges in latent graph:   {g_latent.ecount()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hBTmRvqQIco",
        "outputId": "0b9eba0c-5841-4c3d-e641-3443b47e8d61"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes with greatest connectivity differences:\n",
            "  Node 1352 has 2518 differing connections.\n",
            "  Node 5131 has 2507 differing connections.\n",
            "  Node 3930 has 2500 differing connections.\n",
            "  Node 4552 has 2490 differing connections.\n",
            "  Node 3978 has 2483 differing connections.\n",
            "\n",
            "Total edges in original graph: 4681902\n",
            "Total edges in latent graph:   107336\n"
          ]
        }
      ]
    }
  ]
}